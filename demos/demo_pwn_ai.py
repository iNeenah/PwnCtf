#!/usr/bin/env python3
"""
Demo de PWN AI Analyzer
Muestra todas las capacidades de la herramienta
"""

import os
import sys
import time
import json
from pwn_ai_analyzer import PWNAIAnalyzer

def create_demo_files():
    """Crear archivos de demostraciÃ³n"""
    print("ğŸ“ Creando archivos de demostraciÃ³n...")
    
    demo_dir = "./demo_files"
    os.makedirs(demo_dir, exist_ok=True)
    
    # Archivo con flag oculta
    with open(f"{demo_dir}/secret.txt", "w") as f:
        f.write("""
Este es un archivo de texto normal.
Pero contiene un secreto: flag{demo_text_flag_found}
TambiÃ©n hay informaciÃ³n adicional aquÃ­.
        """)
    
    # CÃ³digo C vulnerable
    c_code = '''#include <stdio.h>
#include <string.h>

void vulnerable_function(char *input) {
    char buffer[64];
    strcpy(buffer, input);  // Vulnerable to buffer overflow
    printf("Input: %s\\n", buffer);
}

int main() {
    char input[256];
    printf("Enter input: ");
    gets(input);  // Another vulnerability
    vulnerable_function(input);
    
    // Hidden flag: flag{demo_c_code_analysis}
    return 0;
}'''
    
    with open(f"{demo_dir}/vulnerable.c", "w") as f:
        f.write(c_code)
    
    # Script Python con vulnerabilidades
    py_code = '''#!/usr/bin/env python3
import os
import subprocess

def process_user_input(user_input):
    # Vulnerable to code injection
    eval(user_input)  # Never do this!
    
    # Another vulnerability
    os.system(f"echo {user_input}")  # Command injection
    
def main():
    user_input = input("Enter command: ")
    process_user_input(user_input)
    
    # Secret flag hidden in comment
    # flag{demo_python_code_injection}

if __name__ == "__main__":
    main()
'''
    
    with open(f"{demo_dir}/vulnerable.py", "w") as f:
        f.write(py_code)
    
    # Archivo HTML con XSS
    html_code = '''<!DOCTYPE html>
<html>
<head>
    <title>Demo Web Page</title>
</head>
<body>
    <h1>Welcome to Demo Page</h1>
    
    <script>
        // Vulnerable to XSS
        function displayUserInput() {
            var input = document.getElementById('userInput').value;
            document.getElementById('output').innerHTML = input;  // XSS vulnerability
        }
        
        // Hidden flag: flag{demo_web_xss_vulnerability}
    </script>
    
    <input type="text" id="userInput" placeholder="Enter text">
    <button onclick="displayUserInput()">Submit</button>
    <div id="output"></div>
</body>
</html>'''
    
    with open(f"{demo_dir}/vulnerable.html", "w") as f:
        f.write(html_code)
    
    # Archivo JSON con datos
    json_data = {
        "users": [
            {"name": "admin", "password": "admin123"},
            {"name": "user", "password": "password"}
        ],
        "config": {
            "debug": True,
            "secret_key": "flag{demo_json_config_leak}",
            "database_url": "mysql://root:password@localhost/app"
        }
    }
    
    with open(f"{demo_dir}/config.json", "w") as f:
        json.dump(json_data, f, indent=2)
    
    print(f"âœ… Archivos de demostraciÃ³n creados en: {demo_dir}")
    return demo_dir

def run_demo_analysis(demo_dir, use_ai=False):
    """Ejecutar anÃ¡lisis de demostraciÃ³n"""
    print("\nğŸ¤– INICIANDO ANÃLISIS DE DEMOSTRACIÃ“N")
    print("=" * 50)
    
    # Crear analizador
    api_key = None
    if use_ai:
        api_key = input("Ingresa tu API key de Gemini (opcional): ").strip()
        if not api_key:
            print("âš ï¸  Continuando sin IA...")
            api_key = None
    
    analyzer = PWNAIAnalyzer(gemini_api_key=api_key)
    
    # Analizar directorio de demostraciÃ³n
    analyzer.analyze_directory(demo_dir)
    
    return analyzer

def show_interactive_demo():
    """Mostrar demo interactivo"""
    print("ğŸ® PWN AI ANALYZER - DEMOSTRACIÃ“N INTERACTIVA")
    print("=" * 60)
    
    print("\nÂ¿QuÃ© te gustarÃ­a hacer?")
    print("1. ğŸ“ Crear archivos de demostraciÃ³n")
    print("2. ğŸ” Analizar archivos existentes")
    print("3. ğŸŒ Iniciar interfaz web")
    print("4. ğŸ“Š Ver ejemplo de resultados")
    print("5. ğŸ¤– Demo completo con IA")
    print("0. âŒ Salir")
    
    while True:
        choice = input("\nSelecciona una opciÃ³n: ").strip()
        
        if choice == "1":
            demo_dir = create_demo_files()
            print(f"\nâœ… Archivos creados. Ahora puedes analizarlos con:")
            print(f"   python pwn_ai_analyzer.py {demo_dir}")
            
        elif choice == "2":
            target = input("Ingresa ruta del archivo o directorio: ").strip()
            if os.path.exists(target):
                analyzer = PWNAIAnalyzer()
                if os.path.isdir(target):
                    analyzer.analyze_directory(target)
                else:
                    analyzer.analyze_single_file(target)
            else:
                print("âŒ Ruta no existe")
                
        elif choice == "3":
            print("ğŸŒ Iniciando interfaz web...")
            print("Ejecuta: python web_pwn_analyzer.py")
            print("Luego ve a: http://localhost:5000")
            
        elif choice == "4":
            show_example_results()
            
        elif choice == "5":
            demo_dir = create_demo_files()
            analyzer = run_demo_analysis(demo_dir, use_ai=True)
            show_analysis_summary(analyzer)
            
        elif choice == "0":
            print("ğŸ‘‹ Â¡Hasta luego!")
            break
            
        else:
            print("âŒ OpciÃ³n invÃ¡lida")

def show_example_results():
    """Mostrar ejemplo de resultados"""
    print("\nğŸ“Š EJEMPLO DE RESULTADOS DE ANÃLISIS")
    print("=" * 40)
    
    example_results = {
        "flags_found": [
            {
                "flag": "flag{demo_buffer_overflow}",
                "source": "./vulnerable_binary",
                "method": "string_analysis"
            },
            {
                "flag": "flag{demo_format_string}",
                "source": "./format_vuln.c",
                "method": "text_analysis"
            }
        ],
        "vulnerabilities": [
            {
                "type": "Buffer Overflow",
                "file": "./vulnerable.c",
                "function": "strcpy",
                "severity": "High"
            },
            {
                "type": "Code Injection",
                "file": "./app.py",
                "function": "eval",
                "severity": "Critical"
            }
        ],
        "analysis_summary": {
            "total_files": 15,
            "flags_found": 7,
            "vulnerabilities": 12,
            "exploits_generated": 3
        }
    }
    
    print("ğŸš© FLAGS ENCONTRADAS:")
    for i, flag in enumerate(example_results["flags_found"], 1):
        print(f"  {i}. {flag['flag']}")
        print(f"     ğŸ“ Fuente: {flag['source']}")
        print(f"     ğŸ” MÃ©todo: {flag['method']}")
        print()
    
    print("âš ï¸  VULNERABILIDADES DETECTADAS:")
    for i, vuln in enumerate(example_results["vulnerabilities"], 1):
        print(f"  {i}. {vuln['type']} ({vuln['severity']})")
        print(f"     ğŸ“ Archivo: {vuln['file']}")
        print(f"     ğŸ”§ FunciÃ³n: {vuln['function']}")
        print()
    
    print("ğŸ“ˆ RESUMEN:")
    summary = example_results["analysis_summary"]
    print(f"  ğŸ“ Archivos analizados: {summary['total_files']}")
    print(f"  ğŸš© Flags encontradas: {summary['flags_found']}")
    print(f"  âš ï¸  Vulnerabilidades: {summary['vulnerabilities']}")
    print(f"  ğŸ”§ Exploits generados: {summary['exploits_generated']}")

def show_analysis_summary(analyzer):
    """Mostrar resumen del anÃ¡lisis"""
    print("\nğŸ“ˆ RESUMEN DEL ANÃLISIS COMPLETADO")
    print("=" * 40)
    
    print(f"ğŸ“ Archivos analizados: {len(analyzer.analysis_results)}")
    print(f"ğŸš© Flags encontradas: {len(analyzer.flags_found)}")
    
    if analyzer.flags_found:
        print("\nğŸ† FLAGS ENCONTRADAS:")
        for i, flag_info in enumerate(analyzer.flags_found, 1):
            flag_text = flag_info.get('flag', flag_info.get('content', 'N/A'))
            print(f"  {i}. {flag_text}")
            print(f"     ğŸ“ {os.path.basename(flag_info['source'])}")
            print()
    
    print(f"\nğŸ“„ Reporte completo guardado en:")
    print(f"   {analyzer.working_directory}/analysis_report.json")
    
    print(f"\nğŸ”§ Exploits generados en:")
    print(f"   {analyzer.working_directory}/exploits/")

def show_help():
    """Mostrar ayuda"""
    print("\nâ“ AYUDA - PWN AI ANALYZER")
    print("=" * 30)
    
    print("\nğŸ¯ MODOS DE USO:")
    print("1. ğŸ“± LÃ­nea de comandos:")
    print("   python pwn_ai_analyzer.py <archivo_o_directorio> [api_key]")
    
    print("\n2. ğŸŒ Interfaz web:")
    print("   python web_pwn_analyzer.py")
    
    print("\n3. ğŸ® Demo interactivo:")
    print("   python demo_pwn_ai.py")
    
    print("\nğŸ”§ FUNCIONALIDADES:")
    print("â€¢ AnÃ¡lisis automÃ¡tico de archivos")
    print("â€¢ DetecciÃ³n de vulnerabilidades")
    print("â€¢ BÃºsqueda automÃ¡tica de flags")
    print("â€¢ GeneraciÃ³n de exploits")
    print("â€¢ Chat con IA (requiere API key)")
    print("â€¢ Interfaz web drag & drop")
    
    print("\nğŸ¤– PARA USAR IA:")
    print("1. Ve a: https://makersuite.google.com/app/apikey")
    print("2. Crea una API key de Gemini")
    print("3. Ãšsala en la herramienta")
    
    print("\nğŸ“ SOPORTE:")
    print("â€¢ GitHub: [URL del repositorio]")
    print("â€¢ Issues: Para reportar bugs")
    print("â€¢ DocumentaciÃ³n: README_PWN_AI.md")

def main():
    """FunciÃ³n principal del demo"""
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help" or sys.argv[1] == "-h":
            show_help()
            return
        elif sys.argv[1] == "--create-demo":
            create_demo_files()
            return
        elif sys.argv[1] == "--example":
            show_example_results()
            return
    
    show_interactive_demo()

if __name__ == "__main__":
    main()